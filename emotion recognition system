pip install tensorflow keras opencv-python numpy matplotlib


"""
Emotion Recognition System using CNN
Author: ChatGPT (GPT-5)
Description: Detects emotions from facial images using Convolutional Neural Networks (CNN).
"""

import cv2
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

# ---------------------------------
# 1. Data Preprocessing
# ---------------------------------

# Dataset structure (example):
# dataset/
# â”œâ”€â”€ train/
# â”‚   â”œâ”€â”€ happy/
# â”‚   â”œâ”€â”€ sad/
# â”‚   â”œâ”€â”€ angry/
# â”‚   â”œâ”€â”€ surprise/
# â”‚   â”œâ”€â”€ neutral/
# â”œâ”€â”€ test/
#     â”œâ”€â”€ happy/
#     â”œâ”€â”€ sad/
#     â”œâ”€â”€ angry/
#     â”œâ”€â”€ surprise/
#     â”œâ”€â”€ neutral/

train_data_path = 'dataset/train'
test_data_path = 'dataset/test'

# Preprocess images
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

test_datagen = ImageDataGenerator(rescale=1.0/255)

train_set = train_datagen.flow_from_directory(
    train_data_path,
    target_size=(48, 48),
    batch_size=32,
    color_mode='grayscale',
    class_mode='categorical'
)

test_set = test_datagen.flow_from_directory(
    test_data_path,
    target_size=(48, 48),
    batch_size=32,
    color_mode='grayscale',
    class_mode='categorical'
)

# ---------------------------------
# 2. Build CNN Model
# ---------------------------------
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(train_set.num_classes, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ---------------------------------
# 3. Train the Model
# ---------------------------------
history = model.fit(
    train_set,
    validation_data=test_set,
    epochs=30
)

# Save the trained model
model.save("emotion_recognition_model.h5")
print("âœ… Model saved as 'emotion_recognition_model.h5'")

# ---------------------------------
# 4. Plot Accuracy and Loss
# ---------------------------------
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.legend()
plt.show()

# ---------------------------------
# 5. Real-Time Emotion Detection (Webcam)
# ---------------------------------
emotion_labels = list(train_set.class_indices.keys())

# Load the model for live detection
from tensorflow.keras.models import load_model
model = load_model("emotion_recognition_model.h5")

face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

cap = cv2.VideoCapture(0)

print("ðŸŽ¥ Starting webcam... Press 'q' to quit.")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)

    for (x, y, w, h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        roi_gray = cv2.resize(roi_gray, (48, 48))
        roi_gray = roi_gray.astype('float') / 255.0
        roi_gray = np.expand_dims(roi_gray, axis=0)
        roi_gray = np.expand_dims(roi_gray, axis=-1)

        prediction = model.predict(roi_gray)[0]
        emotion = emotion_labels[np.argmax(prediction)]

        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)
        cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)

    cv2.imshow('Emotion Recognition', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
